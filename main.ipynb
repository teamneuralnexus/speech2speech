{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COPYING GENERATED SRC_AUDIO AND TGT_AUDIO data ( hindi to english ) generated by third party tts api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /teamspace/studios/this_studio/SRC_AUDIO/train/*.wav /teamspace/studios/this_studio/lastchance/TGT_AUDIO/train/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /teamspace/studios/this_studio/TGT_AUDIO/train/*.wav /teamspace/studios/this_studio/lastchance/SRC_AUDIO/train/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATING SOME SAMPLES FOR TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text-to-speech conversion successful. Audio saved to /teamspace/studios/this_studio/lastchance/SRC_AUDIO/test/infer_1.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "def text_to_speech(text, output_file, lang):\n",
    "    speech_key = \"b55960a2b2c9437a9ec4d48e84a0da21\"  # Replace with your Speech service key\n",
    "    service_region = \"eastus\"  # Replace with your Speech service region\n",
    "    # Create a speech configuration object\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    if(lang==\"hi\"):\n",
    "        speech_config.speech_synthesis_voice_name='hi-IN-MadhurNeural'\n",
    "        \n",
    "    # Create a speech synthesizer object\n",
    "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, )\n",
    "    # Synthesize the text and save it to a file\n",
    "    result = synthesizer.speak_text_async(text).get()\n",
    "    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        audio_data = result.audio_data\n",
    "        with open(output_file, \"wb\") as audio_file:\n",
    "            audio_file.write(audio_data)\n",
    "        print(f'Text-to-speech conversion successful. Audio saved to {output_file}')\n",
    "    else:\n",
    "        print(f'Text-to-speech conversion failed: {result.reason}')\n",
    "# Example usage\n",
    "text_to_speech(\"यह फूल बहुत सुंदर है\", \"/teamspace/studios/this_studio/lastchance/SRC_AUDIO/test/infer_2.wav\", lang=\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text-to-speech conversion successful. Audio saved to /teamspace/studios/this_studio/lastchance/SRC_AUDIO/test/infer_4.wav\n"
     ]
    }
   ],
   "source": [
    "text_to_speech(\"आईआईआईटी दिल्ली आकर मुझे बहुत अच्छा लगा\", \"/teamspace/studios/this_studio/lastchance/SRC_AUDIO/test/infer_4.wav\", lang=\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text-to-speech conversion successful. Audio saved to /teamspace/studios/this_studio/lastchance/TGT_AUDIO/test/infer_4.wav\n"
     ]
    }
   ],
   "source": [
    "text_to_speech(\"I felt pretty nice coming to IIIT Delhi\", \"/teamspace/studios/this_studio/lastchance/TGT_AUDIO/test/infer_4.wav\", lang=\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATING MANIFEST FILES FOR TGT AND SRC AUDIO DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python fairseq/examples/wav2vec/wav2vec_manifest.py /teamspace/studios/this_studio/lastchance/SRC_AUDIO/train --dest /teamspace/studios/this_studio/lastchance/SRC_AUDIO/train --ext wav --valid-percent 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python fairseq/examples/wav2vec/wav2vec_manifest.py /teamspace/studios/this_studio/lastchance/TGT_AUDIO/train --dest /teamspace/studios/this_studio/lastchance/TGT_AUDIO/train --ext wav --valid-percent 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python fairseq/examples/wav2vec/wav2vec_manifest.py /teamspace/studios/this_studio/lastchance/SRC_AUDIO/test --dest /teamspace/studios/this_studio/lastchance/SRC_AUDIO/test --ext wav --valid-percent 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python fairseq/examples/wav2vec/wav2vec_manifest.py /teamspace/studios/this_studio/lastchance/TGT_AUDIO/test --dest /teamspace/studios/this_studio/lastchance/TGT_AUDIO/test --ext wav --valid-percent 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATING UNIT FOR THE TGT_AUDIO i.e ENGLISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 03:52:32 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-03-16 03:52:35 | INFO | __main__ | Namespace(feature_type='hubert', acoustic_model_path='/teamspace/studios/this_studio/models/hubert_base_ls960.pt', layer=6, kmeans_model_path='/teamspace/studios/this_studio/models/km.bin', features_path=None, manifest_path='/teamspace/studios/this_studio/lastchance/TGT_AUDIO/train/train.tsv', out_quantized_file_path='/teamspace/studios/this_studio/lastchance/TGT_AUDIO/train.txt', extension='.wav', channel_id=None, hide_fname=False)\n",
      "2024-03-16 03:52:35 | INFO | __main__ | Extracting hubert acoustic features...\n",
      "2024-03-16 03:52:42 | INFO | fairseq.tasks.hubert_pretraining | current directory is /teamspace/studios/this_studio\n",
      "2024-03-16 03:52:42 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/checkpoint/wnhsu/data/librispeech/960h/iter/250K_50hz_km100_mp0_65_v2', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\n",
      "2024-03-16 03:52:42 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'conv_pos_batch_norm': False, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "100%|█████████████████████████████████████| 11584/11584 [02:00<00:00, 96.43it/s]\n",
      "2024-03-16 03:54:45 | INFO | __main__ | Features extracted for 11584 utterances.\n",
      "\n",
      "2024-03-16 03:54:45 | INFO | __main__ | Dimensionality of representation = 768\n",
      "2024-03-16 03:54:45 | INFO | __main__ | Loading K-means model from /teamspace/studios/this_studio/models/km.bin ...\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator MiniBatchKMeans from version 0.24.0 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "Writing quantized predictions to /teamspace/studios/this_studio/lastchance/TGT_AUDIO/train.txt\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 PYTHONPATH=fairseq/. python /teamspace/studios/this_studio/fairseq/examples/textless_nlp/gslm/speech2unit/clustering/quantize_with_kmeans.py --feature_type hubert --kmeans_model_path /teamspace/studios/this_studio/models/km.bin --acoustic_model_path /teamspace/studios/this_studio/models/hubert_base_ls960.pt --layer 6 --manifest_path /teamspace/studios/this_studio/lastchance/TGT_AUDIO/train/train.tsv --out_quantized_file_path /teamspace/studios/this_studio/lastchance/TGT_AUDIO/train.txt --extension \".wav\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 03:55:08 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-03-16 03:55:10 | INFO | __main__ | Namespace(feature_type='hubert', acoustic_model_path='/teamspace/studios/this_studio/models/hubert_base_ls960.pt', layer=6, kmeans_model_path='/teamspace/studios/this_studio/models/km.bin', features_path=None, manifest_path='/teamspace/studios/this_studio/lastchance/TGT_AUDIO/test/test.tsv', out_quantized_file_path='/teamspace/studios/this_studio/lastchance/TGT_AUDIO/test.txt', extension='.wav', channel_id=None, hide_fname=False)\n",
      "2024-03-16 03:55:10 | INFO | __main__ | Extracting hubert acoustic features...\n",
      "2024-03-16 03:55:14 | INFO | fairseq.tasks.hubert_pretraining | current directory is /teamspace/studios/this_studio\n",
      "2024-03-16 03:55:14 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/checkpoint/wnhsu/data/librispeech/960h/iter/250K_50hz_km100_mp0_65_v2', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\n",
      "2024-03-16 03:55:14 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'conv_pos_batch_norm': False, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00,  4.86it/s]\n",
      "2024-03-16 03:55:18 | INFO | __main__ | Features extracted for 4 utterances.\n",
      "\n",
      "2024-03-16 03:55:18 | INFO | __main__ | Dimensionality of representation = 768\n",
      "2024-03-16 03:55:18 | INFO | __main__ | Loading K-means model from /teamspace/studios/this_studio/models/km.bin ...\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator MiniBatchKMeans from version 0.24.0 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "Writing quantized predictions to /teamspace/studios/this_studio/lastchance/TGT_AUDIO/test.txt\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 PYTHONPATH=fairseq/. python /teamspace/studios/this_studio/fairseq/examples/textless_nlp/gslm/speech2unit/clustering/quantize_with_kmeans.py --feature_type hubert --kmeans_model_path /teamspace/studios/this_studio/models/km.bin --acoustic_model_path /teamspace/studios/this_studio/models/hubert_base_ls960.pt --layer 6 --manifest_path /teamspace/studios/this_studio/lastchance/TGT_AUDIO/test/test.tsv --out_quantized_file_path /teamspace/studios/this_studio/lastchance/TGT_AUDIO/test.txt --extension \".wav\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOADING THE DATASET CONFIGURATION IN A FOLDER CALLED DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 03:55:26 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "Generating manifest...\n",
      "Processing train\n",
      "100%|███████████████████████████████████| 11584/11584 [00:01<00:00, 9063.52it/s]\n",
      "Processed 11584 samples\n",
      "Writing manifest to /teamspace/studios/this_studio/lastchance/DATA_ROOT/train.tsv...\n",
      "Processing test\n",
      "100%|███████████████████████████████████████████| 4/4 [00:00<00:00, 5507.95it/s]\n",
      "Processed 4 samples\n",
      "Writing manifest to /teamspace/studios/this_studio/lastchance/DATA_ROOT/test.tsv...\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 PYTHONPATH=fairseq/. python /teamspace/studios/this_studio/fairseq/examples/speech_to_speech/preprocessing/prep_s2ut_data.py --source-dir /teamspace/studios/this_studio/lastchance/SRC_AUDIO --target-dir /teamspace/studios/this_studio/lastchance/TGT_AUDIO --data-split train test --output-root /teamspace/studios/this_studio/lastchance/DATA_ROOT --reduce-unit --vocoder-checkpoint /teamspace/studios/this_studio/models/g_00500000 --vocoder-cfg /teamspace/studios/this_studio/models/config.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "df = load_dataset(\"cfilt/iitb-english-hindi\", split=\"train[:1%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUNNING THE TRAINING COMMAND ( PREDICTING TGT UNIT FROM INPUT AUDIO )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 04:16:51 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-03-16 04:16:55 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 20000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 20000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 50, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/teamspace/studios/this_studio/lastchance/model', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='speech_to_unit', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='speech_to_speech', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=20000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=True, max_tokens_valid=20000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2ut_transformer_fisher', max_epoch=50, max_update=400000, stop_time_hours=0, clip_norm=10.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/teamspace/studios/this_studio/lastchance/model', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=10, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/teamspace/studios/this_studio/lastchance/DATA_ROOT', config_yaml='/teamspace/studios/this_studio/lastchance/DATA_ROOT/config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=3000, target_is_code=True, target_code_size=100, n_frames_per_step=1, eval_inference=False, eval_args='{}', eos_prob_threshold=0.5, mcd_normalize_type='targ', vocoder='code_hifigan', spec_bwd_max_iter=8, infer_target_lang='', label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, rdrop_alpha=0.0, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=1e-07, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, dropout=0.1, attention_dropout=0.1, activation_dropout=0.1, no_seed_provided=False, encoder_embed_dim=256, encoder_attention_heads=4, encoder_freezing_updates=0, input_channels=1, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_ffn_embed_dim=2048, encoder_layers=12, encoder_normalize_before=True, no_scale_embedding=False, speaker_embed_dim=256, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=True, decoder_learned_pos=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, quant_noise_pq=0, _name='s2ut_transformer_fisher'), 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='speech_to_unit', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='speech_to_speech', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=20000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=True, max_tokens_valid=20000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2ut_transformer_fisher', max_epoch=50, max_update=400000, stop_time_hours=0, clip_norm=10.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/teamspace/studios/this_studio/lastchance/model', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=10, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/teamspace/studios/this_studio/lastchance/DATA_ROOT', config_yaml='/teamspace/studios/this_studio/lastchance/DATA_ROOT/config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=3000, target_is_code=True, target_code_size=100, n_frames_per_step=1, eval_inference=False, eval_args='{}', eos_prob_threshold=0.5, mcd_normalize_type='targ', vocoder='code_hifigan', spec_bwd_max_iter=8, infer_target_lang='', label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, rdrop_alpha=0.0, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=1e-07, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, dropout=0.1, attention_dropout=0.1, activation_dropout=0.1, no_seed_provided=False, encoder_embed_dim=256, encoder_attention_heads=4, encoder_freezing_updates=0, input_channels=1, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_ffn_embed_dim=2048, encoder_layers=12, encoder_normalize_before=True, no_scale_embedding=False, speaker_embed_dim=256, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=True, decoder_learned_pos=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, quant_noise_pq=0, _name='speech_to_speech'), 'criterion': {'_name': 'speech_to_unit', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False, 'rdrop_alpha': 0.0}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 10000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2024-03-16 04:16:55 | INFO | fairseq.tasks.speech_to_speech | dictionary size: 104\n",
      "2024-03-16 04:16:55 | INFO | fairseq_cli.train | S2UTTransformerModel(\n",
      "  (encoder): S2STransformerEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (subsample): Conv1dSubsampler(\n",
      "      (conv_layers): ModuleList(\n",
      "        (0): Conv1d(80, 1024, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "        (1): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "      )\n",
      "    )\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0-11): 12 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerUnitDecoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): StackedEmbedding(104, 256, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (output_projection): Linear(in_features=256, out_features=104, bias=False)\n",
      "  )\n",
      ")\n",
      "2024-03-16 04:16:55 | INFO | fairseq_cli.train | task: SpeechToSpeechTask\n",
      "2024-03-16 04:16:55 | INFO | fairseq_cli.train | model: S2UTTransformerModel\n",
      "2024-03-16 04:16:55 | INFO | fairseq_cli.train | criterion: SpeechToUnitMultitaskTaskCriterion\n",
      "2024-03-16 04:16:55 | INFO | fairseq_cli.train | num. shared model params: 27,002,880 (num. trained: 27,002,880)\n",
      "2024-03-16 04:16:55 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
      "2024-03-16 04:16:55 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
      "2024-03-16 04:16:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2024-03-16 04:16:55 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.748 GB ; name = Tesla T4                                \n",
      "2024-03-16 04:16:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2024-03-16 04:16:55 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
      "2024-03-16 04:16:55 | INFO | fairseq_cli.train | max tokens per device = 20000 and max sentences per device = None\n",
      "2024-03-16 04:16:55 | INFO | fairseq.trainer | Preparing to load checkpoint /teamspace/studios/this_studio/lastchance/model/checkpoint_last.pt\n",
      "2024-03-16 04:16:55 | INFO | fairseq.trainer | No existing checkpoint found /teamspace/studios/this_studio/lastchance/model/checkpoint_last.pt\n",
      "2024-03-16 04:16:55 | INFO | fairseq.trainer | loading train data for epoch 1\n",
      "2024-03-16 04:16:55 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.\n",
      "2024-03-16 04:16:56 | INFO | fairseq.data.audio.speech_to_text_dataset | 'train' has 0.00% OOV\n",
      "2024-03-16 04:16:56 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToSpeechDataset(split=\"train\", n_samples=11_584, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
      "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
      "    SpecAugmentTransform(time_warp_w=0, freq_mask_n=1, freq_mask_f=27, time_mask_n=1, time_mask_t=100, time_mask_p=1.0)\n",
      "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
      "))\n",
      "2024-03-16 04:16:56 | INFO | fairseq.data.audio.speech_to_speech_dataset | SpeechToSpeechDataset(split=\"train\", n_samples=11_584, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
      "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
      "    SpecAugmentTransform(time_warp_w=0, freq_mask_n=1, freq_mask_f=27, time_mask_n=1, time_mask_t=100, time_mask_p=1.0)\n",
      "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
      "))\n",
      "2024-03-16 04:16:56 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:16:56 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n",
      "2024-03-16 04:16:56 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n",
      "2024-03-16 04:16:56 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n",
      "2024-03-16 04:16:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 001:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:16:56 | INFO | fairseq.trainer | begin training epoch 1\n",
      "2024-03-16 04:16:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "2024-03-16 04:16:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0\n",
      "epoch 001:   1%|▎                               | 2/178 [00:01<02:17,  1.28it/s]2024-03-16 04:16:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0\n",
      "epoch 001:   4%|█▍                              | 8/178 [00:02<00:30,  5.52it/s]2024-03-16 04:16:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0\n",
      "2024-03-16 04:17:40 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
      "2024-03-16 04:17:40 | INFO | train | epoch 001 | loss 7.72 | nll_loss 7.659 | ppl 202.11 | wps 12548.4 | ups 4.09 | wpb 3052.9 | bsz 64.9 | num_updates 175 | lr 8.84825e-06 | gnorm 5.254 | clip 18.9 | loss_scale 16 | train_wall 24 | gb_free 12.2 | wall 45\n",
      "2024-03-16 04:17:40 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:17:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 002:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:17:41 | INFO | fairseq.trainer | begin training epoch 2\n",
      "2024-03-16 04:17:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:18:22 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
      "2024-03-16 04:18:22 | INFO | train | epoch 002 | loss 6.263 | nll_loss 6.032 | ppl 65.42 | wps 13124.8 | ups 4.29 | wpb 3060.3 | bsz 65.1 | num_updates 353 | lr 1.77465e-05 | gnorm 0.924 | clip 0 | loss_scale 16 | train_wall 21 | gb_free 12.6 | wall 87\n",
      "2024-03-16 04:18:22 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:18:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 003:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:18:22 | INFO | fairseq.trainer | begin training epoch 3\n",
      "2024-03-16 04:18:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:19:04 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
      "2024-03-16 04:19:04 | INFO | train | epoch 003 | loss 4.752 | nll_loss 3.894 | ppl 14.86 | wps 13086.1 | ups 4.28 | wpb 3060.3 | bsz 65.1 | num_updates 531 | lr 2.66447e-05 | gnorm 1.193 | clip 0 | loss_scale 16 | train_wall 21 | gb_free 12.4 | wall 128\n",
      "2024-03-16 04:19:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:19:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 004:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:19:04 | INFO | fairseq.trainer | begin training epoch 4\n",
      "2024-03-16 04:19:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:19:45 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
      "2024-03-16 04:19:45 | INFO | train | epoch 004 | loss 4.167 | nll_loss 3.058 | ppl 8.33 | wps 13161 | ups 4.3 | wpb 3060.3 | bsz 65.1 | num_updates 709 | lr 3.55429e-05 | gnorm 1.189 | clip 0 | loss_scale 16 | train_wall 21 | gb_free 12.4 | wall 170\n",
      "2024-03-16 04:19:45 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:19:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 005:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:19:45 | INFO | fairseq.trainer | begin training epoch 5\n",
      "2024-03-16 04:19:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:20:27 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
      "2024-03-16 04:20:27 | INFO | train | epoch 005 | loss 4.028 | nll_loss 2.869 | ppl 7.31 | wps 13060 | ups 4.27 | wpb 3060.3 | bsz 65.1 | num_updates 887 | lr 4.44411e-05 | gnorm 1.131 | clip 0 | loss_scale 16 | train_wall 22 | gb_free 12.3 | wall 212\n",
      "2024-03-16 04:20:27 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:20:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 006:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:20:27 | INFO | fairseq.trainer | begin training epoch 6\n",
      "2024-03-16 04:20:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:21:11 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)\n",
      "2024-03-16 04:21:11 | INFO | train | epoch 006 | loss 3.95 | nll_loss 2.765 | ppl 6.8 | wps 12256.8 | ups 4.01 | wpb 3060.3 | bsz 65.1 | num_updates 1065 | lr 5.33394e-05 | gnorm 1.105 | clip 0 | loss_scale 16 | train_wall 22 | gb_free 11.6 | wall 256\n",
      "2024-03-16 04:21:11 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:21:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 007:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:21:11 | INFO | fairseq.trainer | begin training epoch 7\n",
      "2024-03-16 04:21:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:21:53 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)\n",
      "2024-03-16 04:21:53 | INFO | train | epoch 007 | loss 3.895 | nll_loss 2.693 | ppl 6.47 | wps 13120 | ups 4.29 | wpb 3060.3 | bsz 65.1 | num_updates 1243 | lr 6.22376e-05 | gnorm 1.068 | clip 0 | loss_scale 16 | train_wall 21 | gb_free 12.6 | wall 298\n",
      "2024-03-16 04:21:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:21:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 008:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:21:53 | INFO | fairseq.trainer | begin training epoch 8\n",
      "2024-03-16 04:21:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:22:35 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)\n",
      "2024-03-16 04:22:35 | INFO | train | epoch 008 | loss 3.854 | nll_loss 2.639 | ppl 6.23 | wps 12925.4 | ups 4.22 | wpb 3060.3 | bsz 65.1 | num_updates 1421 | lr 7.11358e-05 | gnorm 1.059 | clip 0 | loss_scale 16 | train_wall 22 | gb_free 12.4 | wall 340\n",
      "2024-03-16 04:22:35 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:22:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 009:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:22:35 | INFO | fairseq.trainer | begin training epoch 9\n",
      "2024-03-16 04:22:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "epoch 009:  60%|▌| 106/178 [00:25<00:17,  4.19it/s, loss=3.83, nll_loss=2.609, p2024-03-16 04:23:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0\n",
      "2024-03-16 04:23:16 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)\n",
      "2024-03-16 04:23:16 | INFO | train | epoch 009 | loss 3.809 | nll_loss 2.579 | ppl 5.98 | wps 12980 | ups 4.25 | wpb 3054.6 | bsz 64.9 | num_updates 1598 | lr 7.9984e-05 | gnorm 1.036 | clip 0 | loss_scale 8 | train_wall 21 | gb_free 12.9 | wall 381\n",
      "2024-03-16 04:23:16 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:23:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 010:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:23:17 | INFO | fairseq.trainer | begin training epoch 10\n",
      "2024-03-16 04:23:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "epoch 010:  99%|▉| 177/178 [00:40<00:00,  4.42it/s, loss=3.777, nll_loss=2.536, 2024-03-16 04:23:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1776 updates\n",
      "2024-03-16 04:23:58 | INFO | fairseq.trainer | Saving checkpoint to /teamspace/studios/this_studio/lastchance/model/checkpoint10.pt\n",
      "2024-03-16 04:23:58 | INFO | fairseq.trainer | Finished saving checkpoint to /teamspace/studios/this_studio/lastchance/model/checkpoint10.pt\n",
      "2024-03-16 04:23:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /teamspace/studios/this_studio/lastchance/model/checkpoint10.pt (epoch 10 @ 1776 updates, score None) (writing took 0.8268350109992753 seconds)\n",
      "2024-03-16 04:23:59 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)\n",
      "2024-03-16 04:23:59 | INFO | train | epoch 010 | loss 3.768 | nll_loss 2.526 | ppl 5.76 | wps 12946.4 | ups 4.23 | wpb 3060.3 | bsz 65.1 | num_updates 1776 | lr 8.88822e-05 | gnorm 1.003 | clip 0 | loss_scale 8 | train_wall 21 | gb_free 12.3 | wall 423\n",
      "2024-03-16 04:23:59 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:23:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 011:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:23:59 | INFO | fairseq.trainer | begin training epoch 11\n",
      "2024-03-16 04:23:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:24:41 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)\n",
      "2024-03-16 04:24:41 | INFO | train | epoch 011 | loss 3.729 | nll_loss 2.473 | ppl 5.55 | wps 12786.8 | ups 4.18 | wpb 3060.3 | bsz 65.1 | num_updates 1954 | lr 9.77805e-05 | gnorm 0.989 | clip 0 | loss_scale 8 | train_wall 22 | gb_free 12.5 | wall 466\n",
      "2024-03-16 04:24:41 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:24:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 012:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:24:41 | INFO | fairseq.trainer | begin training epoch 12\n",
      "2024-03-16 04:24:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:25:22 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)\n",
      "2024-03-16 04:25:22 | INFO | train | epoch 012 | loss 3.689 | nll_loss 2.419 | ppl 5.35 | wps 13174.5 | ups 4.3 | wpb 3060.3 | bsz 65.1 | num_updates 2132 | lr 0.000106679 | gnorm 0.965 | clip 0 | loss_scale 8 | train_wall 22 | gb_free 12.2 | wall 507\n",
      "2024-03-16 04:25:22 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:25:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 013:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:25:23 | INFO | fairseq.trainer | begin training epoch 13\n",
      "2024-03-16 04:25:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:26:04 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)\n",
      "2024-03-16 04:26:04 | INFO | train | epoch 013 | loss 3.65 | nll_loss 2.367 | ppl 5.16 | wps 13148.3 | ups 4.3 | wpb 3060.3 | bsz 65.1 | num_updates 2310 | lr 0.000115577 | gnorm 0.997 | clip 0 | loss_scale 8 | train_wall 21 | gb_free 12.4 | wall 549\n",
      "2024-03-16 04:26:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:26:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 014:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:26:04 | INFO | fairseq.trainer | begin training epoch 14\n",
      "2024-03-16 04:26:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:26:45 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)\n",
      "2024-03-16 04:26:45 | INFO | train | epoch 014 | loss 3.61 | nll_loss 2.314 | ppl 4.97 | wps 13261.6 | ups 4.33 | wpb 3060.3 | bsz 65.1 | num_updates 2488 | lr 0.000124475 | gnorm 0.936 | clip 0 | loss_scale 8 | train_wall 21 | gb_free 12.5 | wall 590\n",
      "2024-03-16 04:26:45 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:26:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 015:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:26:45 | INFO | fairseq.trainer | begin training epoch 15\n",
      "2024-03-16 04:26:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:27:28 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)\n",
      "2024-03-16 04:27:28 | INFO | train | epoch 015 | loss 3.576 | nll_loss 2.268 | ppl 4.82 | wps 12788.9 | ups 4.18 | wpb 3060.3 | bsz 65.1 | num_updates 2666 | lr 0.000133373 | gnorm 0.925 | clip 0 | loss_scale 8 | train_wall 22 | gb_free 12.4 | wall 632\n",
      "2024-03-16 04:27:28 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:27:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 016:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:27:28 | INFO | fairseq.trainer | begin training epoch 16\n",
      "2024-03-16 04:27:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:28:09 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)\n",
      "2024-03-16 04:28:09 | INFO | train | epoch 016 | loss 3.538 | nll_loss 2.218 | ppl 4.65 | wps 13116.9 | ups 4.29 | wpb 3060.3 | bsz 65.1 | num_updates 2844 | lr 0.000142272 | gnorm 0.953 | clip 0 | loss_scale 8 | train_wall 21 | gb_free 12.2 | wall 674\n",
      "2024-03-16 04:28:09 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:28:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 017:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:28:09 | INFO | fairseq.trainer | begin training epoch 17\n",
      "2024-03-16 04:28:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:28:50 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)\n",
      "2024-03-16 04:28:50 | INFO | train | epoch 017 | loss 3.502 | nll_loss 2.169 | ppl 4.5 | wps 13167.2 | ups 4.3 | wpb 3060.3 | bsz 65.1 | num_updates 3022 | lr 0.00015117 | gnorm 0.907 | clip 0 | loss_scale 8 | train_wall 21 | gb_free 12.1 | wall 715\n",
      "2024-03-16 04:28:50 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:28:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 018:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:28:51 | INFO | fairseq.trainer | begin training epoch 18\n",
      "2024-03-16 04:28:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:29:32 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)\n",
      "2024-03-16 04:29:32 | INFO | train | epoch 018 | loss 3.471 | nll_loss 2.126 | ppl 4.37 | wps 13231.2 | ups 4.32 | wpb 3060.3 | bsz 65.1 | num_updates 3200 | lr 0.000160068 | gnorm 0.9 | clip 0 | loss_scale 8 | train_wall 21 | gb_free 12.2 | wall 757\n",
      "2024-03-16 04:29:32 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:29:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 019:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:29:32 | INFO | fairseq.trainer | begin training epoch 19\n",
      "2024-03-16 04:29:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:30:13 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)\n",
      "2024-03-16 04:30:13 | INFO | train | epoch 019 | loss 3.434 | nll_loss 2.076 | ppl 4.22 | wps 13146.7 | ups 4.3 | wpb 3060.3 | bsz 65.1 | num_updates 3378 | lr 0.000168966 | gnorm 0.899 | clip 0 | loss_scale 8 | train_wall 22 | gb_free 12.4 | wall 798\n",
      "2024-03-16 04:30:13 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:30:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 020:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:30:13 | INFO | fairseq.trainer | begin training epoch 20\n",
      "2024-03-16 04:30:13 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "epoch 020:  26%|▎| 47/178 [00:10<00:32,  4.04it/s, loss=3.42, nll_loss=2.058, pp2024-03-16 04:30:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0\n",
      "epoch 020:  99%|▉| 177/178 [00:41<00:00,  4.57it/s, loss=3.41, nll_loss=2.045, p2024-03-16 04:30:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3555 updates\n",
      "2024-03-16 04:30:55 | INFO | fairseq.trainer | Saving checkpoint to /teamspace/studios/this_studio/lastchance/model/checkpoint20.pt\n",
      "2024-03-16 04:30:55 | INFO | fairseq.trainer | Finished saving checkpoint to /teamspace/studios/this_studio/lastchance/model/checkpoint20.pt\n",
      "2024-03-16 04:30:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /teamspace/studios/this_studio/lastchance/model/checkpoint20.pt (epoch 20 @ 3555 updates, score None) (writing took 1.1542357700000139 seconds)\n",
      "2024-03-16 04:30:56 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)\n",
      "2024-03-16 04:30:56 | INFO | train | epoch 020 | loss 3.402 | nll_loss 2.033 | ppl 4.09 | wps 12667.8 | ups 4.15 | wpb 3053.5 | bsz 64.8 | num_updates 3555 | lr 0.000177814 | gnorm 0.872 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.9 | wall 841\n",
      "2024-03-16 04:30:56 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:30:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 021:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:30:56 | INFO | fairseq.trainer | begin training epoch 21\n",
      "2024-03-16 04:30:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:31:39 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)\n",
      "2024-03-16 04:31:39 | INFO | train | epoch 021 | loss 3.366 | nll_loss 1.985 | ppl 3.96 | wps 12734.8 | ups 4.16 | wpb 3060.3 | bsz 65.1 | num_updates 3733 | lr 0.000186713 | gnorm 0.955 | clip 0.6 | loss_scale 4 | train_wall 22 | gb_free 12.4 | wall 883\n",
      "2024-03-16 04:31:39 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:31:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 022:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:31:39 | INFO | fairseq.trainer | begin training epoch 22\n",
      "2024-03-16 04:31:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:32:20 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)\n",
      "2024-03-16 04:32:20 | INFO | train | epoch 022 | loss 3.334 | nll_loss 1.94 | ppl 3.84 | wps 13205.1 | ups 4.31 | wpb 3060.3 | bsz 65.1 | num_updates 3911 | lr 0.000195611 | gnorm 0.919 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.1 | wall 925\n",
      "2024-03-16 04:32:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:32:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 023:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:32:20 | INFO | fairseq.trainer | begin training epoch 23\n",
      "2024-03-16 04:32:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:33:01 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)\n",
      "2024-03-16 04:33:01 | INFO | train | epoch 023 | loss 3.301 | nll_loss 1.897 | ppl 3.72 | wps 13268.4 | ups 4.34 | wpb 3060.3 | bsz 65.1 | num_updates 4089 | lr 0.000204509 | gnorm 0.839 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12 | wall 966\n",
      "2024-03-16 04:33:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:33:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 024:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:33:01 | INFO | fairseq.trainer | begin training epoch 24\n",
      "2024-03-16 04:33:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:33:42 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)\n",
      "2024-03-16 04:33:42 | INFO | train | epoch 024 | loss 3.269 | nll_loss 1.85 | ppl 3.61 | wps 13288.6 | ups 4.34 | wpb 3060.3 | bsz 65.1 | num_updates 4267 | lr 0.000213407 | gnorm 0.861 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.4 | wall 1007\n",
      "2024-03-16 04:33:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:33:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 025:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:33:42 | INFO | fairseq.trainer | begin training epoch 25\n",
      "2024-03-16 04:33:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:34:23 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)\n",
      "2024-03-16 04:34:23 | INFO | train | epoch 025 | loss 3.236 | nll_loss 1.807 | ppl 3.5 | wps 13205.3 | ups 4.31 | wpb 3060.3 | bsz 65.1 | num_updates 4445 | lr 0.000222306 | gnorm 0.814 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.5 | wall 1048\n",
      "2024-03-16 04:34:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:34:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 026:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:34:23 | INFO | fairseq.trainer | begin training epoch 26\n",
      "2024-03-16 04:34:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:35:04 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)\n",
      "2024-03-16 04:35:04 | INFO | train | epoch 026 | loss 3.203 | nll_loss 1.761 | ppl 3.39 | wps 13234 | ups 4.32 | wpb 3060.3 | bsz 65.1 | num_updates 4623 | lr 0.000231204 | gnorm 0.828 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 13.4 | wall 1089\n",
      "2024-03-16 04:35:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:35:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 027:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:35:04 | INFO | fairseq.trainer | begin training epoch 27\n",
      "2024-03-16 04:35:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:35:45 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)\n",
      "2024-03-16 04:35:45 | INFO | train | epoch 027 | loss 3.168 | nll_loss 1.713 | ppl 3.28 | wps 13238.6 | ups 4.33 | wpb 3060.3 | bsz 65.1 | num_updates 4801 | lr 0.000240102 | gnorm 0.812 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.8 | wall 1130\n",
      "2024-03-16 04:35:45 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:35:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 028:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:35:45 | INFO | fairseq.trainer | begin training epoch 28\n",
      "2024-03-16 04:35:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:36:27 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)\n",
      "2024-03-16 04:36:27 | INFO | train | epoch 028 | loss 3.139 | nll_loss 1.675 | ppl 3.19 | wps 13161.5 | ups 4.3 | wpb 3060.3 | bsz 65.1 | num_updates 4979 | lr 0.000249 | gnorm 0.793 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.3 | wall 1172\n",
      "2024-03-16 04:36:27 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:36:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 029:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:36:27 | INFO | fairseq.trainer | begin training epoch 29\n",
      "2024-03-16 04:36:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:37:08 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)\n",
      "2024-03-16 04:37:08 | INFO | train | epoch 029 | loss 3.109 | nll_loss 1.634 | ppl 3.1 | wps 13286.3 | ups 4.34 | wpb 3060.3 | bsz 65.1 | num_updates 5157 | lr 0.000257898 | gnorm 0.793 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.8 | wall 1213\n",
      "2024-03-16 04:37:08 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:37:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 030:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:37:08 | INFO | fairseq.trainer | begin training epoch 30\n",
      "2024-03-16 04:37:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "epoch 030:  99%|▉| 177/178 [00:41<00:00,  4.83it/s, loss=3.069, nll_loss=1.578, 2024-03-16 04:37:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 5335 updates\n",
      "2024-03-16 04:37:49 | INFO | fairseq.trainer | Saving checkpoint to /teamspace/studios/this_studio/lastchance/model/checkpoint30.pt\n",
      "2024-03-16 04:37:50 | INFO | fairseq.trainer | Finished saving checkpoint to /teamspace/studios/this_studio/lastchance/model/checkpoint30.pt\n",
      "2024-03-16 04:37:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /teamspace/studios/this_studio/lastchance/model/checkpoint30.pt (epoch 30 @ 5335 updates, score None) (writing took 1.1724610870005563 seconds)\n",
      "2024-03-16 04:37:50 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)\n",
      "2024-03-16 04:37:50 | INFO | train | epoch 030 | loss 3.074 | nll_loss 1.585 | ppl 3 | wps 12806.7 | ups 4.18 | wpb 3060.3 | bsz 65.1 | num_updates 5335 | lr 0.000266797 | gnorm 0.788 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.1 | wall 1255\n",
      "2024-03-16 04:37:50 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:37:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 031:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:37:50 | INFO | fairseq.trainer | begin training epoch 31\n",
      "2024-03-16 04:37:50 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:38:33 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)\n",
      "2024-03-16 04:38:33 | INFO | train | epoch 031 | loss 3.045 | nll_loss 1.548 | ppl 2.92 | wps 12699.6 | ups 4.15 | wpb 3060.3 | bsz 65.1 | num_updates 5513 | lr 0.000275695 | gnorm 0.778 | clip 0 | loss_scale 4 | train_wall 22 | gb_free 12.5 | wall 1298\n",
      "2024-03-16 04:38:33 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:38:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 032:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:38:33 | INFO | fairseq.trainer | begin training epoch 32\n",
      "2024-03-16 04:38:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:39:15 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)\n",
      "2024-03-16 04:39:15 | INFO | train | epoch 032 | loss 3.02 | nll_loss 1.513 | ppl 2.85 | wps 13182 | ups 4.31 | wpb 3060.3 | bsz 65.1 | num_updates 5691 | lr 0.000284593 | gnorm 0.768 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 13.4 | wall 1339\n",
      "2024-03-16 04:39:15 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:39:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 033:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:39:15 | INFO | fairseq.trainer | begin training epoch 33\n",
      "2024-03-16 04:39:15 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:39:56 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)\n",
      "2024-03-16 04:39:56 | INFO | train | epoch 033 | loss 2.983 | nll_loss 1.465 | ppl 2.76 | wps 12992.5 | ups 4.25 | wpb 3060.3 | bsz 65.1 | num_updates 5869 | lr 0.000293491 | gnorm 0.744 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.3 | wall 1381\n",
      "2024-03-16 04:39:56 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:39:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 034:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:39:57 | INFO | fairseq.trainer | begin training epoch 34\n",
      "2024-03-16 04:39:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:40:38 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)\n",
      "2024-03-16 04:40:38 | INFO | train | epoch 034 | loss 2.956 | nll_loss 1.428 | ppl 2.69 | wps 13121 | ups 4.29 | wpb 3060.3 | bsz 65.1 | num_updates 6047 | lr 0.00030239 | gnorm 0.945 | clip 0.6 | loss_scale 4 | train_wall 21 | gb_free 13.4 | wall 1423\n",
      "2024-03-16 04:40:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:40:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 035:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:40:38 | INFO | fairseq.trainer | begin training epoch 35\n",
      "2024-03-16 04:40:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:41:19 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)\n",
      "2024-03-16 04:41:19 | INFO | train | epoch 035 | loss 2.931 | nll_loss 1.396 | ppl 2.63 | wps 13285.2 | ups 4.34 | wpb 3060.3 | bsz 65.1 | num_updates 6225 | lr 0.000311288 | gnorm 0.738 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.5 | wall 1464\n",
      "2024-03-16 04:41:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:41:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 036:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:41:19 | INFO | fairseq.trainer | begin training epoch 36\n",
      "2024-03-16 04:41:19 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:42:00 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)\n",
      "2024-03-16 04:42:00 | INFO | train | epoch 036 | loss 2.901 | nll_loss 1.357 | ppl 2.56 | wps 13346.3 | ups 4.36 | wpb 3060.3 | bsz 65.1 | num_updates 6403 | lr 0.000320186 | gnorm 0.724 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.4 | wall 1505\n",
      "2024-03-16 04:42:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:42:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 037:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:42:00 | INFO | fairseq.trainer | begin training epoch 37\n",
      "2024-03-16 04:42:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:42:41 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)\n",
      "2024-03-16 04:42:41 | INFO | train | epoch 037 | loss 2.875 | nll_loss 1.323 | ppl 2.5 | wps 13218.4 | ups 4.32 | wpb 3060.3 | bsz 65.1 | num_updates 6581 | lr 0.000329084 | gnorm 0.707 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.3 | wall 1546\n",
      "2024-03-16 04:42:41 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:42:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 038:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:42:41 | INFO | fairseq.trainer | begin training epoch 38\n",
      "2024-03-16 04:42:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:43:22 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)\n",
      "2024-03-16 04:43:22 | INFO | train | epoch 038 | loss 2.853 | nll_loss 1.295 | ppl 2.45 | wps 13138.2 | ups 4.29 | wpb 3060.3 | bsz 65.1 | num_updates 6759 | lr 0.000337982 | gnorm 0.706 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.5 | wall 1587\n",
      "2024-03-16 04:43:22 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:43:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 039:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:43:23 | INFO | fairseq.trainer | begin training epoch 39\n",
      "2024-03-16 04:43:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:44:04 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)\n",
      "2024-03-16 04:44:04 | INFO | train | epoch 039 | loss 2.83 | nll_loss 1.265 | ppl 2.4 | wps 13108.5 | ups 4.28 | wpb 3060.3 | bsz 65.1 | num_updates 6937 | lr 0.000346881 | gnorm 0.705 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.2 | wall 1629\n",
      "2024-03-16 04:44:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:44:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 040:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:44:04 | INFO | fairseq.trainer | begin training epoch 40\n",
      "2024-03-16 04:44:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "epoch 040:  99%|▉| 177/178 [00:40<00:00,  4.00it/s, loss=2.814, nll_loss=1.243, 2024-03-16 04:44:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 7115 updates\n",
      "2024-03-16 04:44:45 | INFO | fairseq.trainer | Saving checkpoint to /teamspace/studios/this_studio/lastchance/model/checkpoint40.pt\n",
      "2024-03-16 04:44:46 | INFO | fairseq.trainer | Finished saving checkpoint to /teamspace/studios/this_studio/lastchance/model/checkpoint40.pt\n",
      "2024-03-16 04:44:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /teamspace/studios/this_studio/lastchance/model/checkpoint40.pt (epoch 40 @ 7115 updates, score None) (writing took 1.1560733189999155 seconds)\n",
      "2024-03-16 04:44:46 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)\n",
      "2024-03-16 04:44:46 | INFO | train | epoch 040 | loss 2.804 | nll_loss 1.232 | ppl 2.35 | wps 12845.2 | ups 4.2 | wpb 3060.3 | bsz 65.1 | num_updates 7115 | lr 0.000355779 | gnorm 0.687 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.5 | wall 1671\n",
      "2024-03-16 04:44:46 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:44:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 041:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:44:47 | INFO | fairseq.trainer | begin training epoch 41\n",
      "2024-03-16 04:44:47 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:45:29 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)\n",
      "2024-03-16 04:45:29 | INFO | train | epoch 041 | loss 2.79 | nll_loss 1.215 | ppl 2.32 | wps 12699.6 | ups 4.15 | wpb 3060.3 | bsz 65.1 | num_updates 7293 | lr 0.000364677 | gnorm 0.69 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.5 | wall 1714\n",
      "2024-03-16 04:45:29 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:45:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 042:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:45:29 | INFO | fairseq.trainer | begin training epoch 42\n",
      "2024-03-16 04:45:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:46:10 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)\n",
      "2024-03-16 04:46:10 | INFO | train | epoch 042 | loss 2.766 | nll_loss 1.185 | ppl 2.27 | wps 13238.8 | ups 4.33 | wpb 3060.3 | bsz 65.1 | num_updates 7471 | lr 0.000373575 | gnorm 0.665 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12 | wall 1755\n",
      "2024-03-16 04:46:10 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:46:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 043:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:46:11 | INFO | fairseq.trainer | begin training epoch 43\n",
      "2024-03-16 04:46:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:46:52 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)\n",
      "2024-03-16 04:46:52 | INFO | train | epoch 043 | loss 2.743 | nll_loss 1.155 | ppl 2.23 | wps 13209.9 | ups 4.32 | wpb 3060.3 | bsz 65.1 | num_updates 7649 | lr 0.000382474 | gnorm 0.66 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 13.4 | wall 1797\n",
      "2024-03-16 04:46:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:46:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 044:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:46:52 | INFO | fairseq.trainer | begin training epoch 44\n",
      "2024-03-16 04:46:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:47:33 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)\n",
      "2024-03-16 04:47:33 | INFO | train | epoch 044 | loss 2.732 | nll_loss 1.144 | ppl 2.21 | wps 13076.5 | ups 4.27 | wpb 3060.3 | bsz 65.1 | num_updates 7827 | lr 0.000391372 | gnorm 0.662 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.4 | wall 1838\n",
      "2024-03-16 04:47:33 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:47:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 045:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:47:33 | INFO | fairseq.trainer | begin training epoch 45\n",
      "2024-03-16 04:47:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:48:15 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)\n",
      "2024-03-16 04:48:15 | INFO | train | epoch 045 | loss 2.716 | nll_loss 1.123 | ppl 2.18 | wps 13191.4 | ups 4.31 | wpb 3060.3 | bsz 65.1 | num_updates 8005 | lr 0.00040027 | gnorm 0.656 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.6 | wall 1880\n",
      "2024-03-16 04:48:15 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:48:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 046:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:48:15 | INFO | fairseq.trainer | begin training epoch 46\n",
      "2024-03-16 04:48:15 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:48:56 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)\n",
      "2024-03-16 04:48:56 | INFO | train | epoch 046 | loss 2.692 | nll_loss 1.093 | ppl 2.13 | wps 13201 | ups 4.31 | wpb 3060.3 | bsz 65.1 | num_updates 8183 | lr 0.000409168 | gnorm 0.64 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.6 | wall 1921\n",
      "2024-03-16 04:48:56 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:48:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 047:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:48:56 | INFO | fairseq.trainer | begin training epoch 47\n",
      "2024-03-16 04:48:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:49:37 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)\n",
      "2024-03-16 04:49:37 | INFO | train | epoch 047 | loss 2.679 | nll_loss 1.078 | ppl 2.11 | wps 13213.1 | ups 4.32 | wpb 3060.3 | bsz 65.1 | num_updates 8361 | lr 0.000418066 | gnorm 0.653 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 13 | wall 1962\n",
      "2024-03-16 04:49:37 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:49:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 048:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:49:37 | INFO | fairseq.trainer | begin training epoch 48\n",
      "2024-03-16 04:49:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:50:20 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)\n",
      "2024-03-16 04:50:20 | INFO | train | epoch 048 | loss 2.668 | nll_loss 1.067 | ppl 2.09 | wps 12778.4 | ups 4.18 | wpb 3060.3 | bsz 65.1 | num_updates 8539 | lr 0.000426965 | gnorm 0.63 | clip 0 | loss_scale 4 | train_wall 22 | gb_free 12.3 | wall 2005\n",
      "2024-03-16 04:50:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:50:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 049:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:50:20 | INFO | fairseq.trainer | begin training epoch 49\n",
      "2024-03-16 04:50:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "2024-03-16 04:51:01 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)\n",
      "2024-03-16 04:51:01 | INFO | train | epoch 049 | loss 2.644 | nll_loss 1.036 | ppl 2.05 | wps 13305.4 | ups 4.35 | wpb 3060.3 | bsz 65.1 | num_updates 8717 | lr 0.000435863 | gnorm 0.622 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.3 | wall 2046\n",
      "2024-03-16 04:51:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:51:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 178\n",
      "epoch 050:   0%|                                        | 0/178 [00:00<?, ?it/s]2024-03-16 04:51:01 | INFO | fairseq.trainer | begin training epoch 50\n",
      "2024-03-16 04:51:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "epoch 050:  99%|▉| 177/178 [00:40<00:00,  4.43it/s, loss=2.636, nll_loss=1.029, 2024-03-16 04:51:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 8895 updates\n",
      "2024-03-16 04:51:42 | INFO | fairseq.trainer | Saving checkpoint to /teamspace/studios/this_studio/lastchance/model/checkpoint50.pt\n",
      "2024-03-16 04:51:42 | INFO | fairseq.trainer | Finished saving checkpoint to /teamspace/studios/this_studio/lastchance/model/checkpoint50.pt\n",
      "2024-03-16 04:51:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /teamspace/studios/this_studio/lastchance/model/checkpoint50.pt (epoch 50 @ 8895 updates, score None) (writing took 1.2657043550007074 seconds)\n",
      "2024-03-16 04:51:43 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)\n",
      "2024-03-16 04:51:43 | INFO | train | epoch 050 | loss 2.634 | nll_loss 1.026 | ppl 2.04 | wps 12936.7 | ups 4.23 | wpb 3060.3 | bsz 65.1 | num_updates 8895 | lr 0.000444761 | gnorm 0.626 | clip 0 | loss_scale 4 | train_wall 21 | gb_free 12.6 | wall 2088\n",
      "2024-03-16 04:51:43 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 04:51:43 | INFO | fairseq_cli.train | done training in 2086.8 seconds\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 fairseq-train /teamspace/studios/this_studio/lastchance/DATA_ROOT \\\n",
    "  --config-yaml /teamspace/studios/this_studio/lastchance/DATA_ROOT/config.yaml \\\n",
    "  --task speech_to_speech --target-is-code --target-code-size 100 --vocoder code_hifigan  \\\n",
    "  --criterion speech_to_unit --label-smoothing 0.2 \\\n",
    "  --arch s2ut_transformer_fisher --share-decoder-input-output-embed \\\n",
    "  --dropout 0.1 --attention-dropout 0.1 --relu-dropout 0.1 \\\n",
    "  --train-subset train --disable-validation \\\n",
    "  --save-dir /teamspace/studios/this_studio/lastchance/model \\\n",
    "  --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-init-lr 1e-7 --warmup-updates 10000 \\\n",
    "  --optimizer adam --adam-betas \"(0.9,0.98)\" --clip-norm 10.0 \\\n",
    "  --max-update 400000 --max-tokens 20000 --max-target-positions 3000 --update-freq 1 \\\n",
    "  --seed 1 --fp16 --num-workers 1 --max-epoch 50 --save-interval 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUNNING INFERENCE ON TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 05:11:38 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-03-16 05:11:42 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/teamspace/studios/this_studio/lastchance/model/checkpoint_last.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': '/teamspace/studios/this_studio/lastchance/results'}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 50000, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 1.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all'}, 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='speech_to_speech', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=1, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=1, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, path='/teamspace/studios/this_studio/lastchance/model/checkpoint_last.pt', post_process=None, quiet=False, model_overrides='{}', results_path='/teamspace/studios/this_studio/lastchance/results', beam=10, beam_mt=0, nbest=1, max_len_a=1.0, max_len_b=200, max_len_a_mt=0, max_len_b_mt=200, min_len=1, match_source_len=False, unnormalized=False, no_early_stop=False, no_beamable_mm=False, lenpen=1, lenpen_mt=1, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=None, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, no_seed_provided=False, eos_token=None, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, arch='wav2vec2', data='/teamspace/studios/this_studio/lastchance/DATA_ROOT', config_yaml='/teamspace/studios/this_studio/lastchance/DATA_ROOT/config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, target_is_code=True, target_code_size=100, n_frames_per_step=1, eval_inference=False, eval_args='{}', eos_prob_threshold=0.5, mcd_normalize_type='targ', vocoder='code_hifigan', spec_bwd_max_iter=8, infer_target_lang='', force_anneal=None, lr_shrink=0.1, warmup_updates=0, pad=1, eos=2, unk=3, _name='speech_to_speech'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2024-03-16 05:11:42 | INFO | fairseq.tasks.speech_to_speech | dictionary size: 104\n",
      "2024-03-16 05:11:42 | INFO | fairseq_cli.generate | loading model(s) from /teamspace/studios/this_studio/lastchance/model/checkpoint_last.pt\n",
      "2024-03-16 05:11:43 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.\n",
      "2024-03-16 05:11:43 | INFO | fairseq.data.audio.speech_to_text_dataset | 'test' has 0.00% OOV\n",
      "2024-03-16 05:11:43 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToSpeechDataset(split=\"test\", n_samples=4, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
      "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
      "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
      "))\n",
      "2024-03-16 05:11:43 | INFO | fairseq.data.audio.speech_to_speech_dataset | SpeechToSpeechDataset(split=\"test\", n_samples=4, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
      "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
      "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
      "))\n",
      "2024-03-16 05:11:43 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-03-16 05:11:43 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n",
      "2024-03-16 05:11:43 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n",
      "2024-03-16 05:11:43 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n",
      "2024-03-16 05:11:46 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2024-03-16 05:11:46 | INFO | fairseq_cli.generate | Translated 3 sentences (147 tokens) in 2.6s (1.14 sentences/s, 56.04 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "!fairseq-generate /teamspace/studios/this_studio/lastchance/DATA_ROOT \\\n",
    "  --config-yaml /teamspace/studios/this_studio/lastchance/DATA_ROOT/config.yaml \\\n",
    "  --task speech_to_speech --target-is-code --target-code-size 100 --vocoder code_hifigan \\\n",
    "  --path /teamspace/studios/this_studio/lastchance/model/checkpoint_last.pt  --gen-subset test \\\n",
    "  --max-tokens 50000 \\\n",
    "  --beam 10 --max-len-a 1 \\\n",
    "  --results-path /teamspace/studios/this_studio/lastchance/results \\\n",
    "  --batch-size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /teamspace/studios/this_studio/fairseq/fairseq_cli/generate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep \"^D\\-\" /teamspace/studios/this_studio/lastchance/results/generate-test.txt | \\\n",
    "  sed 's/^D-//ig' | sort -nk1 | cut -f3 \\\n",
    "  > /teamspace/studios/this_studio/lastchance/results/generate-test.unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATING SPEECH SAMPLES FROM GENERATED WAVEFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 05:20:04 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-03-16 05:20:07 | INFO | __main__ | Namespace(in_code_file='/teamspace/studios/this_studio/lastchance/results/generate-test.unit', vocoder='/teamspace/studios/this_studio/models/g_00500000', vocoder_cfg='/teamspace/studios/this_studio/models/config.json', results_path='/teamspace/studios/this_studio/lastchance/results', dur_prediction=True, speaker_id=-1, cpu=False)\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "Removing weight norm...\n",
      "2024-03-16 05:20:07 | INFO | fairseq.models.text_to_speech.vocoder | loaded CodeHiFiGAN checkpoint from /teamspace/studios/this_studio/models/g_00500000\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:01<00:00,  2.66it/s]\n"
     ]
    }
   ],
   "source": [
    "!python fairseq/examples/speech_to_speech/generate_waveform_from_code.py \\\n",
    "  --in-code-file /teamspace/studios/this_studio/lastchance/results/generate-test.unit \\\n",
    "  --vocoder /teamspace/studios/this_studio/models/g_00500000 --vocoder-cfg /teamspace/studios/this_studio/models/config.json \\\n",
    "  --results-path /teamspace/studios/this_studio/lastchance/results --dur-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
